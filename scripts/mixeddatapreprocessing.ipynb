{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validation_test_split(files_per_weather, train_percent=0.8, validation_percent=0.1, test_percent=0.1):\n",
    "    \"\"\"Splits the dataset into train, validation, and test sets for each weather condition.\"\"\"\n",
    "    assert train_percent + validation_percent + test_percent == 1.0, \"Splits must sum to 1.\"\n",
    "\n",
    "    train_indices, validation_indices, test_indices = {}, {}, {}\n",
    "\n",
    "    for weather, files in files_per_weather.items():\n",
    "        num_files = len(files)\n",
    "        train_size = int(num_files * train_percent)\n",
    "        validation_size = int(num_files * validation_percent)\n",
    "\n",
    "        shuffled_files = np.random.permutation(files)\n",
    "        train_indices[weather] = shuffled_files[:train_size]\n",
    "        validation_indices[weather] = shuffled_files[train_size:train_size + validation_size]\n",
    "        test_indices[weather] = shuffled_files[train_size + validation_size:]\n",
    "\n",
    "    return train_indices, validation_indices, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_odgt(raw_folders, seg_folders, raw_data, annotated_data, train, validate, test, output_dir):\n",
    "    datasets = {\n",
    "        'train': train,\n",
    "        'validate': validate,\n",
    "        'test': test\n",
    "    }\n",
    "    odgt_files = {key: open(os.path.join(output_dir, f'{key}.odgt'), 'w') for key in datasets.keys()}\n",
    "\n",
    "    for weather, files in raw_data.items():\n",
    "        valid_files = [f for f in files if f.endswith('.png') and f.split('.')[0].isdigit()]\n",
    "        for raw in valid_files:\n",
    "            try:\n",
    "                raw_index = int(raw.split('.')[0])\n",
    "            except ValueError:\n",
    "                print(f\"Skipping {raw} in {weather}\")\n",
    "                continue\n",
    "            raw_path = os.path.abspath(os.path.join(raw_folders[weather], raw))\n",
    "            ann_path = os.path.abspath(os.path.join(seg_folders[weather], raw))\n",
    "\n",
    "            # Debugging statements\n",
    "            if not os.path.exists(raw_path):\n",
    "                print(f\"Raw file not found: {raw_path}\")\n",
    "                continue\n",
    "            if not os.path.exists(ann_path):\n",
    "                print(f\"Annotation file not found: {ann_path}\")\n",
    "                continue\n",
    "\n",
    "            raw_img = Image.open(raw_path)\n",
    "            ann_img = Image.open(ann_path)\n",
    "            assert raw_img.size == ann_img.size, f\"Size mismatch for {raw} in {weather}\"\n",
    "\n",
    "            odgt_line = json.dumps({\n",
    "                \"fpath_img\": raw_path,\n",
    "                \"fpath_segm\": ann_path,\n",
    "                \"width\": raw_img.width,\n",
    "                \"height\": raw_img.height,\n",
    "                \"weather\": weather  # Store weather condition in metadata\n",
    "            })\n",
    "\n",
    "            for key, indices in datasets.items():\n",
    "                if raw_index in indices[weather]:\n",
    "                    odgt_files[key].write(odgt_line + '\\n')\n",
    "\n",
    "    for f in odgt_files.values():\n",
    "        f.close()\n",
    "\n",
    "# Define paths\n",
    "data_root_dir = '/home/zhaob/Desktop/semantic-segmentation-pytorch/1_17_clear_day_mixed'\n",
    "weather_conditions = [\"_outRaw\", \"_outRaw_foggy\", \"_outRaw_night\"]\n",
    "raw_folders = {w: os.path.join(data_root_dir, w) for w in weather_conditions}\n",
    "seg_folders = {w: os.path.join(data_root_dir, w.replace(\"_outRaw\", \"_outSeg\")) for w in weather_conditions}\n",
    "\n",
    "# Collect all files\n",
    "files_per_weather = {w: sorted(os.listdir(raw_folders[w])) for w in weather_conditions}\n",
    "\n",
    "# Prepare raw_data and annotated_data dictionaries\n",
    "raw_data = {w: [f for f in os.listdir(raw_folders[w]) if f.endswith('.png') and os.path.isfile(os.path.join(raw_folders[w], f))] for w in weather_conditions}\n",
    "annotated_data = {w: [f for f in os.listdir(seg_folders[w]) if f.endswith('.png') and os.path.isfile(os.path.join(seg_folders[w], f))] for w in weather_conditions}\n",
    "\n",
    "# Split dataset\n",
    "def train_validation_test_split(files_per_weather):\n",
    "    train = {w: [] for w in weather_conditions}\n",
    "    validate = {w: [] for w in weather_conditions}\n",
    "    test = {w: [] for w in weather_conditions}\n",
    "    for weather, files in files_per_weather.items():\n",
    "        total_files = len(files)\n",
    "        train[weather] = list(range(0, int(0.7 * total_files)))\n",
    "        validate[weather] = list(range(int(0.7 * total_files), int(0.85 * total_files)))\n",
    "        test[weather] = list(range(int(0.85 * total_files), total_files))\n",
    "    return train, validate, test\n",
    "\n",
    "train, validate, test = train_validation_test_split(files_per_weather)\n",
    "\n",
    "# Create ODGT\n",
    "make_odgt(raw_folders, seg_folders, raw_data, annotated_data, train, validate, test, 'odgt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv4ad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
